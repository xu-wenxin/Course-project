{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data as da\n",
    "\n",
    "# additional package sklearn + pandas + plot + seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 dataset\n",
    "The data set was read using the data.py file and broken up and sliced into training and test sets, normalised using z-socre, and noisy using PCA to reduce and raise the dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set shape:  (3918, 11)\n",
      "test set shape:      (980, 11)\n"
     ]
    }
   ],
   "source": [
    "data_pro=da.Data()\n",
    "data=data_pro.read_data()\n",
    "xs,ys=data_pro.split_x_y(data)\n",
    "xs_trans, xs_pca = data_pro.data_noise(10,xs)\n",
    "xs, xs_train, xs_test, ys_train, ys_test = data_pro.data_processing(xs_pca,ys,True)\n",
    "\n",
    "print('training set shape: ',xs_train.shape)\n",
    "print('test set shape:     ', xs_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 KNN\n",
    "For the training set data use the KNeighborsRegressor(), a k-nearest neighbour (KNN) algorithm in sklearn.\n",
    "#### 2.1 find best parameter\n",
    "using GridSearchCV() in sklearn, which use cross-validated method,to determine the optimal parameters in knn method, where the search parameters (param_grid) are set as the assignment parameters (weights), k-values (n_neighbors) and distance calculation methods (metric), and n_neighbors is set to an odd number from 1-69<br/>\n",
    "Output the best parameters and scores for the training set fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters is {'metric': 'cosine', 'n_neighbors': 41, 'weights': 'distance'}\n",
      "score of parameter is 0.5009061479085019\n"
     ]
    }
   ],
   "source": [
    "# 2. knn\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# 2.1 find best hyper-parameter values; k-fold on training set\n",
    "param_grid = [{\n",
    "    'weights': [\"uniform\", \"distance\"],\n",
    "    'n_neighbors': range(1,70,2),\n",
    "    'metric':['euclidean', 'manhattan', 'cosine']\n",
    "}]\n",
    "\n",
    "knn_reg = KNeighborsRegressor()\n",
    "knn_search = GridSearchCV(knn_reg, param_grid,n_jobs=-1)\n",
    "knn_search.fit(xs_train, ys_train)\n",
    "\n",
    "print(\"The best parameters is\",knn_search.best_params_)\n",
    "print('score of parameter is',knn_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 test dataset\n",
    "Assign the optimal parameters to KNeighborsRegressor() as above, fit (.fit) predict (.predict) to the test and training sets, and output its fit score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score of KNN  trian set 1.0\n",
      "Test score of KNN  test set 0.4659363083084658 \n",
      "\n",
      "Train mean error of KNN  trian set 0.0\n",
      "Test mean error of KNN  test set 0.4535910741600085 \n",
      "\n",
      "Train R2 of KNN  trian set 1.0\n",
      "Test R2 score of KNN  test set 0.45905417857011865\n"
     ]
    }
   ],
   "source": [
    "# 2.2 use best parameter on test set\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "knn_reg = KNeighborsRegressor(metric='cosine', n_neighbors=41, weights='distance')\n",
    "\n",
    "knn_reg.fit(xs_train, ys_train)\n",
    "\n",
    "ys_train_pred = knn_reg.predict(xs_train)\n",
    "ys_test_pred = knn_reg.predict(xs_test)\n",
    "\n",
    "#2.3 fit result\n",
    "import fit_result\n",
    "fit_result.score('KNN', ys_train, ys_train_pred,ys_test, ys_test_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 SVM\n",
    "Since the linear kernal operation for a support vector machine (SVM) using GridSearchCV() takes a very long time, this program tries to run it for 6 hours using 7 parameters and did not get results.<br/>\n",
    "The program divides the linear (linear) and non-linear Gaussian kernel functions (rbf) of the SVM into two separate parts for Grid Search and compares the scores to select the optimal parameters and kernel functions, where kernal rbf uses SVR() and kernal linear uses LinearSVR(). The latter linear kernel function algorithm is more efficient than the libsvr-based SVR algorithm and can scale almost linearly to millions of samples and features [https://scikit-learn.org/stable/modules/svm.html#complexity (1.4.4)].<br/>\n",
    "Special, more noisy observationsshould decrease C value, decreasing C corresponds to more regularization, and larger C values will take more time to train, sometimes up to 10 times longer.\n",
    "GridSearchCV() in the last two paragraphs sets n_jobs=-1 to use all processors and increase the speed of computing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters is {'C': 1, 'epsilon': 0.1, 'tol': 0.1}\n",
      "R2 score of parameter is 0.3791132691035906\n"
     ]
    }
   ],
   "source": [
    "# 3 SVM\n",
    "# 3.1 find best parameter\n",
    "# 3.1.1 find best hyper-parameter C values for SVM(kernal=rbf)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "parameters = [\n",
    "    {\n",
    "        'C': [0.001,0.01,0.1,1,10,100,1000,float(\"inf\")],\n",
    "        'tol':[0.001,0.01,0.1,1,10],\n",
    "        'epsilon':[0.01,0.1,1,10]\n",
    "    }\n",
    "]\n",
    "\n",
    "svc_search = GridSearchCV(SVR(kernel='rbf'),parameters,n_jobs=-1) \n",
    "svc_search.fit(xs_train, ys_train)\n",
    "\n",
    "print(\"The best parameters is\",svc_search.best_params_)\n",
    "print('R2 score of parameter is',svc_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters is {'C': 1, 'epsilon': 0.01, 'tol': 0.001}\n",
      "score of parameter is 0.27021640529488894\n"
     ]
    }
   ],
   "source": [
    "# 3.1.2 use LinearSVR to find the best hyper-parameter C values for SVR (kernal=linear)\n",
    "from sklearn.svm import LinearSVR\n",
    "\n",
    "parameters = [\n",
    "    {\n",
    "        'C': [0.0001,0.001,0.1,1,10,100,1000,float(\"inf\")],\n",
    "        'tol':[0.001,0.01,0.1,1,10],\n",
    "        'epsilon':[0.01,0.1,1,10]\n",
    "    }\n",
    "]\n",
    "\n",
    "svc_search = GridSearchCV(LinearSVR(),parameters,n_jobs=-1)\n",
    "svc_search.fit(xs_train, ys_train)\n",
    "\n",
    "print(\"The best parameters is\",svc_search.best_params_)\n",
    "print('score of parameter is',svc_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the optimal parameters and scores of the two methods, we found that for the SVM method kernel=\"rbf\", C=1 gives a better fit, so we assigns SVC() to the test and training sets and performs the fitting prediction and score calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score of SVM  trian set 0.4919518716978365\n",
      "Test score of SVM  test set 0.37427014450047025 \n",
      "\n",
      "Train mean error of SVM  trian set 0.4502472119109347\n",
      "Test mean error of SVM  test set 0.5608808544606592 \n",
      "\n",
      "Train R2 of SVM  trian set 0.4905883459751398\n",
      "Test R2 score of SVM  test set 0.37405297171928886\n"
     ]
    }
   ],
   "source": [
    "# 3.2 use best parameter on test set\n",
    "# 通过score of parameter看出rbf比linear的预测效果更好\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "svr_reg = SVR(kernel=\"rbf\", C=1, tol=0.1, epsilon=0.1)\n",
    "\n",
    "svr_fit = svr_reg.fit(xs_train, ys_train)\n",
    "\n",
    "ys_train_pred = svr_fit.predict(xs_train)\n",
    "ys_test_pred = svr_fit.predict(xs_test)\n",
    "\n",
    "# 3.3 result of svm\n",
    "import fit_result\n",
    "fit_result.score('SVM', ys_train, ys_train_pred,ys_test, ys_test_pred)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3241565c77375f7d3295c2caf706c572c6b79d0b2e7d0d156f0cd07598ad6b7b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('machine')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
