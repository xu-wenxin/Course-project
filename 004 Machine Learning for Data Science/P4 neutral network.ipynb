{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b863ed2-25f4-4d5f-bc61-074e7e45aa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import data as da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ead915a4-08a9-49c2-8491-cbcd7293c31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. data processing\n",
    "# 1.1 load the data\n",
    "\n",
    "data_pro=da.Data()\n",
    "df=data_pro.read_data()\n",
    "\n",
    "# 1.2 scale and sparate the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "xscaler = StandardScaler()\n",
    "yscaler = StandardScaler()\n",
    "X_scaler = xscaler.fit(df.iloc[:,:-1].values)\n",
    "Y_scaler = yscaler.fit(df.iloc[:,-1].values.reshape(-1,1))\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(df.iloc[:,:-1].values,df.iloc[:,-1].values.reshape(-1,1),test_size=.2,random_state=0)\n",
    "\n",
    "# 1.3 transform x and y into pytorch format\n",
    "from torchvision import transforms\n",
    "\n",
    "X_train_scaler = xscaler.transform(X_train)\n",
    "X_test_scaler = xscaler.transform(X_test)\n",
    "y_train_scaler = yscaler.transform(y_train)\n",
    "y_test_scaler = yscaler.transform(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c4fc4a8-cfb8-4229-bdb5-7e5ab03e47d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define and train a Multi-Layer Perceptron \n",
    "class MLPRegressor(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(MLPRegressor, self).__init__()\n",
    "        self.hidden1 = nn.Linear(input_size, 25)\n",
    "        self.hidden2 = nn.Linear(25, 15)\n",
    "        self.hidden3 = nn.Linear(15, output_size)\n",
    "    # defines the forward pass\n",
    "    def forward(self, input):\n",
    "        x = F.relu(self.hidden1(input))\n",
    "        x = F.relu(self.hidden2(x))\n",
    "        return self.hidden3(x)\n",
    "# instantiate this model \n",
    "model = MLPRegressor(X_train_scaler.shape[1], y_train_scaler.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "957b8355-e4e5-4928-ba5f-7f52f2f37df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate an iterator for the training & testing datasets\n",
    "train_dataloader = DataLoader(TensorDataset(torch.tensor(X_train_scaler).float(), torch.tensor(y_train_scaler).float()), batch_size = 2000, shuffle = False)\n",
    "test_dataloader = DataLoader(TensorDataset(torch.tensor(X_test_scaler).float(), torch.tensor(y_test_scaler).float()), batch_size = 1000, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04d290ab-0f7b-48bd-98df-ca3dddd08df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimize the parameters of the model\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.5)\n",
    "loss_function = nn.MSELoss()\n",
    "\n",
    "def train(epoch, train_loader):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        # loss function\n",
    "        loss=loss_function(output, target)\n",
    "        # backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        print('train epoch: {} [{}/{} ({:.0f}%)\\tLoss: {:.6f}]'.format(\n",
    "            epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "            100.*batch_idx / len(train_loader), loss.item()))\n",
    "        \n",
    "def test(test_loader):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        for data, target in test_loader:\n",
    "            output = model(data)\n",
    "            test_loss += F.mse_loss(target, output)\n",
    "        print('test loss: {:.4f}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77031ffa-a5dd-4d4a-bd1f-1a3f27b51361",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 0 [0/3918 (0%)\tLoss: 0.972858]\n",
      "train epoch: 0 [1918/3918 (50%)\tLoss: 0.968778]\n",
      "test loss: 1.0840\n",
      "train epoch: 1 [0/3918 (0%)\tLoss: 0.916492]\n",
      "train epoch: 1 [1918/3918 (50%)\tLoss: 0.936886]\n",
      "test loss: 1.0640\n",
      "train epoch: 2 [0/3918 (0%)\tLoss: 0.885615]\n",
      "train epoch: 2 [1918/3918 (50%)\tLoss: 0.914433]\n",
      "test loss: 1.0457\n",
      "train epoch: 3 [0/3918 (0%)\tLoss: 0.861892]\n",
      "train epoch: 3 [1918/3918 (50%)\tLoss: 0.893460]\n",
      "test loss: 1.0263\n",
      "train epoch: 4 [0/3918 (0%)\tLoss: 0.840063]\n",
      "train epoch: 4 [1918/3918 (50%)\tLoss: 0.872468]\n",
      "test loss: 1.0062\n",
      "train epoch: 5 [0/3918 (0%)\tLoss: 0.818908]\n",
      "train epoch: 5 [1918/3918 (50%)\tLoss: 0.851601]\n",
      "test loss: 0.9862\n",
      "train epoch: 6 [0/3918 (0%)\tLoss: 0.798434]\n",
      "train epoch: 6 [1918/3918 (50%)\tLoss: 0.831464]\n",
      "test loss: 0.9670\n",
      "train epoch: 7 [0/3918 (0%)\tLoss: 0.779247]\n",
      "train epoch: 7 [1918/3918 (50%)\tLoss: 0.812708]\n",
      "test loss: 0.9493\n",
      "train epoch: 8 [0/3918 (0%)\tLoss: 0.761762]\n",
      "train epoch: 8 [1918/3918 (50%)\tLoss: 0.795654]\n",
      "test loss: 0.9332\n",
      "train epoch: 9 [0/3918 (0%)\tLoss: 0.746145]\n",
      "train epoch: 9 [1918/3918 (50%)\tLoss: 0.780593]\n",
      "test loss: 0.9189\n",
      "train epoch: 10 [0/3918 (0%)\tLoss: 0.732427]\n",
      "train epoch: 10 [1918/3918 (50%)\tLoss: 0.767412]\n",
      "test loss: 0.9064\n",
      "train epoch: 11 [0/3918 (0%)\tLoss: 0.720579]\n",
      "train epoch: 11 [1918/3918 (50%)\tLoss: 0.756025]\n",
      "test loss: 0.8956\n",
      "train epoch: 12 [0/3918 (0%)\tLoss: 0.710329]\n",
      "train epoch: 12 [1918/3918 (50%)\tLoss: 0.746252]\n",
      "test loss: 0.8863\n",
      "train epoch: 13 [0/3918 (0%)\tLoss: 0.701429]\n",
      "train epoch: 13 [1918/3918 (50%)\tLoss: 0.737845]\n",
      "test loss: 0.8784\n",
      "train epoch: 14 [0/3918 (0%)\tLoss: 0.693617]\n",
      "train epoch: 14 [1918/3918 (50%)\tLoss: 0.730568]\n",
      "test loss: 0.8717\n",
      "train epoch: 15 [0/3918 (0%)\tLoss: 0.686927]\n",
      "train epoch: 15 [1918/3918 (50%)\tLoss: 0.724306]\n",
      "test loss: 0.8657\n",
      "train epoch: 16 [0/3918 (0%)\tLoss: 0.681086]\n",
      "train epoch: 16 [1918/3918 (50%)\tLoss: 0.718797]\n",
      "test loss: 0.8604\n",
      "train epoch: 17 [0/3918 (0%)\tLoss: 0.675910]\n",
      "train epoch: 17 [1918/3918 (50%)\tLoss: 0.714022]\n",
      "test loss: 0.8558\n",
      "train epoch: 18 [0/3918 (0%)\tLoss: 0.671392]\n",
      "train epoch: 18 [1918/3918 (50%)\tLoss: 0.709830]\n",
      "test loss: 0.8515\n",
      "train epoch: 19 [0/3918 (0%)\tLoss: 0.667422]\n",
      "train epoch: 19 [1918/3918 (50%)\tLoss: 0.706152]\n",
      "test loss: 0.8479\n",
      "train epoch: 20 [0/3918 (0%)\tLoss: 0.663883]\n",
      "train epoch: 20 [1918/3918 (50%)\tLoss: 0.702880]\n",
      "test loss: 0.8446\n",
      "train epoch: 21 [0/3918 (0%)\tLoss: 0.660711]\n",
      "train epoch: 21 [1918/3918 (50%)\tLoss: 0.699938]\n",
      "test loss: 0.8417\n",
      "train epoch: 22 [0/3918 (0%)\tLoss: 0.657873]\n",
      "train epoch: 22 [1918/3918 (50%)\tLoss: 0.697426]\n",
      "test loss: 0.8391\n",
      "train epoch: 23 [0/3918 (0%)\tLoss: 0.655348]\n",
      "train epoch: 23 [1918/3918 (50%)\tLoss: 0.695224]\n",
      "test loss: 0.8366\n",
      "train epoch: 24 [0/3918 (0%)\tLoss: 0.653083]\n",
      "train epoch: 24 [1918/3918 (50%)\tLoss: 0.693253]\n",
      "test loss: 0.8344\n",
      "train epoch: 25 [0/3918 (0%)\tLoss: 0.651018]\n",
      "train epoch: 25 [1918/3918 (50%)\tLoss: 0.691437]\n",
      "test loss: 0.8323\n",
      "train epoch: 26 [0/3918 (0%)\tLoss: 0.649095]\n",
      "train epoch: 26 [1918/3918 (50%)\tLoss: 0.689784]\n",
      "test loss: 0.8303\n",
      "train epoch: 27 [0/3918 (0%)\tLoss: 0.647293]\n",
      "train epoch: 27 [1918/3918 (50%)\tLoss: 0.688236]\n",
      "test loss: 0.8284\n",
      "train epoch: 28 [0/3918 (0%)\tLoss: 0.645631]\n",
      "train epoch: 28 [1918/3918 (50%)\tLoss: 0.686785]\n",
      "test loss: 0.8267\n",
      "train epoch: 29 [0/3918 (0%)\tLoss: 0.644070]\n",
      "train epoch: 29 [1918/3918 (50%)\tLoss: 0.685451]\n",
      "test loss: 0.8250\n",
      "train epoch: 30 [0/3918 (0%)\tLoss: 0.642608]\n",
      "train epoch: 30 [1918/3918 (50%)\tLoss: 0.684207]\n",
      "test loss: 0.8235\n",
      "train epoch: 31 [0/3918 (0%)\tLoss: 0.641197]\n",
      "train epoch: 31 [1918/3918 (50%)\tLoss: 0.683057]\n",
      "test loss: 0.8220\n",
      "train epoch: 32 [0/3918 (0%)\tLoss: 0.639880]\n",
      "train epoch: 32 [1918/3918 (50%)\tLoss: 0.681968]\n",
      "test loss: 0.8207\n",
      "train epoch: 33 [0/3918 (0%)\tLoss: 0.638640]\n",
      "train epoch: 33 [1918/3918 (50%)\tLoss: 0.680937]\n",
      "test loss: 0.8193\n",
      "train epoch: 34 [0/3918 (0%)\tLoss: 0.637487]\n",
      "train epoch: 34 [1918/3918 (50%)\tLoss: 0.679951]\n",
      "test loss: 0.8180\n",
      "train epoch: 35 [0/3918 (0%)\tLoss: 0.636346]\n",
      "train epoch: 35 [1918/3918 (50%)\tLoss: 0.679007]\n",
      "test loss: 0.8168\n",
      "train epoch: 36 [0/3918 (0%)\tLoss: 0.635265]\n",
      "train epoch: 36 [1918/3918 (50%)\tLoss: 0.678080]\n",
      "test loss: 0.8156\n",
      "train epoch: 37 [0/3918 (0%)\tLoss: 0.634194]\n",
      "train epoch: 37 [1918/3918 (50%)\tLoss: 0.677192]\n",
      "test loss: 0.8145\n",
      "train epoch: 38 [0/3918 (0%)\tLoss: 0.633176]\n",
      "train epoch: 38 [1918/3918 (50%)\tLoss: 0.676313]\n",
      "test loss: 0.8134\n",
      "train epoch: 39 [0/3918 (0%)\tLoss: 0.632168]\n",
      "train epoch: 39 [1918/3918 (50%)\tLoss: 0.675459]\n",
      "test loss: 0.8123\n",
      "train epoch: 40 [0/3918 (0%)\tLoss: 0.631194]\n",
      "train epoch: 40 [1918/3918 (50%)\tLoss: 0.674615]\n",
      "test loss: 0.8112\n",
      "train epoch: 41 [0/3918 (0%)\tLoss: 0.630236]\n",
      "train epoch: 41 [1918/3918 (50%)\tLoss: 0.673802]\n",
      "test loss: 0.8102\n",
      "train epoch: 42 [0/3918 (0%)\tLoss: 0.629282]\n",
      "train epoch: 42 [1918/3918 (50%)\tLoss: 0.672989]\n",
      "test loss: 0.8091\n",
      "train epoch: 43 [0/3918 (0%)\tLoss: 0.628328]\n",
      "train epoch: 43 [1918/3918 (50%)\tLoss: 0.672236]\n",
      "test loss: 0.8081\n",
      "train epoch: 44 [0/3918 (0%)\tLoss: 0.627402]\n",
      "train epoch: 44 [1918/3918 (50%)\tLoss: 0.671466]\n",
      "test loss: 0.8071\n",
      "train epoch: 45 [0/3918 (0%)\tLoss: 0.626479]\n",
      "train epoch: 45 [1918/3918 (50%)\tLoss: 0.670703]\n",
      "test loss: 0.8061\n",
      "train epoch: 46 [0/3918 (0%)\tLoss: 0.625572]\n",
      "train epoch: 46 [1918/3918 (50%)\tLoss: 0.669963]\n",
      "test loss: 0.8051\n",
      "train epoch: 47 [0/3918 (0%)\tLoss: 0.624636]\n",
      "train epoch: 47 [1918/3918 (50%)\tLoss: 0.669233]\n",
      "test loss: 0.8041\n",
      "train epoch: 48 [0/3918 (0%)\tLoss: 0.623747]\n",
      "train epoch: 48 [1918/3918 (50%)\tLoss: 0.668505]\n",
      "test loss: 0.8031\n",
      "train epoch: 49 [0/3918 (0%)\tLoss: 0.622856]\n",
      "train epoch: 49 [1918/3918 (50%)\tLoss: 0.667783]\n",
      "test loss: 0.8021\n",
      "train epoch: 50 [0/3918 (0%)\tLoss: 0.622001]\n",
      "train epoch: 50 [1918/3918 (50%)\tLoss: 0.666456]\n",
      "test loss: 0.8021\n",
      "train epoch: 51 [0/3918 (0%)\tLoss: 0.621303]\n",
      "train epoch: 51 [1918/3918 (50%)\tLoss: 0.666221]\n",
      "test loss: 0.8018\n",
      "train epoch: 52 [0/3918 (0%)\tLoss: 0.620780]\n",
      "train epoch: 52 [1918/3918 (50%)\tLoss: 0.665917]\n",
      "test loss: 0.8014\n",
      "train epoch: 53 [0/3918 (0%)\tLoss: 0.620314]\n",
      "train epoch: 53 [1918/3918 (50%)\tLoss: 0.665581]\n",
      "test loss: 0.8010\n",
      "train epoch: 54 [0/3918 (0%)\tLoss: 0.619872]\n",
      "train epoch: 54 [1918/3918 (50%)\tLoss: 0.665234]\n",
      "test loss: 0.8005\n",
      "train epoch: 55 [0/3918 (0%)\tLoss: 0.619441]\n",
      "train epoch: 55 [1918/3918 (50%)\tLoss: 0.664878]\n",
      "test loss: 0.8000\n",
      "train epoch: 56 [0/3918 (0%)\tLoss: 0.619003]\n",
      "train epoch: 56 [1918/3918 (50%)\tLoss: 0.664511]\n",
      "test loss: 0.7995\n",
      "train epoch: 57 [0/3918 (0%)\tLoss: 0.618545]\n",
      "train epoch: 57 [1918/3918 (50%)\tLoss: 0.664148]\n",
      "test loss: 0.7991\n",
      "train epoch: 58 [0/3918 (0%)\tLoss: 0.618092]\n",
      "train epoch: 58 [1918/3918 (50%)\tLoss: 0.663774]\n",
      "test loss: 0.7986\n",
      "train epoch: 59 [0/3918 (0%)\tLoss: 0.617633]\n",
      "train epoch: 59 [1918/3918 (50%)\tLoss: 0.663412]\n",
      "test loss: 0.7981\n",
      "train epoch: 60 [0/3918 (0%)\tLoss: 0.617186]\n",
      "train epoch: 60 [1918/3918 (50%)\tLoss: 0.663038]\n",
      "test loss: 0.7976\n",
      "train epoch: 61 [0/3918 (0%)\tLoss: 0.616732]\n",
      "train epoch: 61 [1918/3918 (50%)\tLoss: 0.662667]\n",
      "test loss: 0.7971\n",
      "train epoch: 62 [0/3918 (0%)\tLoss: 0.616288]\n",
      "train epoch: 62 [1918/3918 (50%)\tLoss: 0.662298]\n",
      "test loss: 0.7966\n",
      "train epoch: 63 [0/3918 (0%)\tLoss: 0.615849]\n",
      "train epoch: 63 [1918/3918 (50%)\tLoss: 0.661931]\n",
      "test loss: 0.7962\n",
      "train epoch: 64 [0/3918 (0%)\tLoss: 0.615415]\n",
      "train epoch: 64 [1918/3918 (50%)\tLoss: 0.661567]\n",
      "test loss: 0.7957\n",
      "train epoch: 65 [0/3918 (0%)\tLoss: 0.614981]\n",
      "train epoch: 65 [1918/3918 (50%)\tLoss: 0.661196]\n",
      "test loss: 0.7952\n",
      "train epoch: 66 [0/3918 (0%)\tLoss: 0.614548]\n",
      "train epoch: 66 [1918/3918 (50%)\tLoss: 0.660826]\n",
      "test loss: 0.7947\n",
      "train epoch: 67 [0/3918 (0%)\tLoss: 0.614122]\n",
      "train epoch: 67 [1918/3918 (50%)\tLoss: 0.660453]\n",
      "test loss: 0.7942\n",
      "train epoch: 68 [0/3918 (0%)\tLoss: 0.613693]\n",
      "train epoch: 68 [1918/3918 (50%)\tLoss: 0.660082]\n",
      "test loss: 0.7937\n",
      "train epoch: 69 [0/3918 (0%)\tLoss: 0.613268]\n",
      "train epoch: 69 [1918/3918 (50%)\tLoss: 0.659711]\n",
      "test loss: 0.7932\n",
      "train epoch: 70 [0/3918 (0%)\tLoss: 0.612842]\n",
      "train epoch: 70 [1918/3918 (50%)\tLoss: 0.659344]\n",
      "test loss: 0.7927\n",
      "train epoch: 71 [0/3918 (0%)\tLoss: 0.612424]\n",
      "train epoch: 71 [1918/3918 (50%)\tLoss: 0.658988]\n",
      "test loss: 0.7922\n",
      "train epoch: 72 [0/3918 (0%)\tLoss: 0.612014]\n",
      "train epoch: 72 [1918/3918 (50%)\tLoss: 0.658627]\n",
      "test loss: 0.7917\n",
      "train epoch: 73 [0/3918 (0%)\tLoss: 0.611599]\n",
      "train epoch: 73 [1918/3918 (50%)\tLoss: 0.658273]\n",
      "test loss: 0.7912\n",
      "train epoch: 74 [0/3918 (0%)\tLoss: 0.611187]\n",
      "train epoch: 74 [1918/3918 (50%)\tLoss: 0.657913]\n",
      "test loss: 0.7908\n",
      "train epoch: 75 [0/3918 (0%)\tLoss: 0.610783]\n",
      "train epoch: 75 [1918/3918 (50%)\tLoss: 0.657560]\n",
      "test loss: 0.7903\n",
      "train epoch: 76 [0/3918 (0%)\tLoss: 0.610384]\n",
      "train epoch: 76 [1918/3918 (50%)\tLoss: 0.657208]\n",
      "test loss: 0.7898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 77 [0/3918 (0%)\tLoss: 0.609996]\n",
      "train epoch: 77 [1918/3918 (50%)\tLoss: 0.656860]\n",
      "test loss: 0.7894\n",
      "train epoch: 78 [0/3918 (0%)\tLoss: 0.609617]\n",
      "train epoch: 78 [1918/3918 (50%)\tLoss: 0.656511]\n",
      "test loss: 0.7889\n",
      "train epoch: 79 [0/3918 (0%)\tLoss: 0.609250]\n",
      "train epoch: 79 [1918/3918 (50%)\tLoss: 0.656165]\n",
      "test loss: 0.7885\n",
      "train epoch: 80 [0/3918 (0%)\tLoss: 0.608880]\n",
      "train epoch: 80 [1918/3918 (50%)\tLoss: 0.655824]\n",
      "test loss: 0.7880\n",
      "train epoch: 81 [0/3918 (0%)\tLoss: 0.608512]\n",
      "train epoch: 81 [1918/3918 (50%)\tLoss: 0.655475]\n",
      "test loss: 0.7876\n",
      "train epoch: 82 [0/3918 (0%)\tLoss: 0.608148]\n",
      "train epoch: 82 [1918/3918 (50%)\tLoss: 0.655133]\n",
      "test loss: 0.7872\n",
      "train epoch: 83 [0/3918 (0%)\tLoss: 0.607800]\n",
      "train epoch: 83 [1918/3918 (50%)\tLoss: 0.654805]\n",
      "test loss: 0.7868\n",
      "train epoch: 84 [0/3918 (0%)\tLoss: 0.607461]\n",
      "train epoch: 84 [1918/3918 (50%)\tLoss: 0.654470]\n",
      "test loss: 0.7864\n",
      "train epoch: 85 [0/3918 (0%)\tLoss: 0.607132]\n",
      "train epoch: 85 [1918/3918 (50%)\tLoss: 0.654128]\n",
      "test loss: 0.7860\n",
      "train epoch: 86 [0/3918 (0%)\tLoss: 0.606815]\n",
      "train epoch: 86 [1918/3918 (50%)\tLoss: 0.653788]\n",
      "test loss: 0.7857\n",
      "train epoch: 87 [0/3918 (0%)\tLoss: 0.606499]\n",
      "train epoch: 87 [1918/3918 (50%)\tLoss: 0.653450]\n",
      "test loss: 0.7853\n",
      "train epoch: 88 [0/3918 (0%)\tLoss: 0.606191]\n",
      "train epoch: 88 [1918/3918 (50%)\tLoss: 0.653113]\n",
      "test loss: 0.7849\n",
      "train epoch: 89 [0/3918 (0%)\tLoss: 0.605887]\n",
      "train epoch: 89 [1918/3918 (50%)\tLoss: 0.652774]\n",
      "test loss: 0.7845\n",
      "train epoch: 90 [0/3918 (0%)\tLoss: 0.605587]\n",
      "train epoch: 90 [1918/3918 (50%)\tLoss: 0.652442]\n",
      "test loss: 0.7841\n",
      "train epoch: 91 [0/3918 (0%)\tLoss: 0.605289]\n",
      "train epoch: 91 [1918/3918 (50%)\tLoss: 0.652114]\n",
      "test loss: 0.7836\n",
      "train epoch: 92 [0/3918 (0%)\tLoss: 0.604992]\n",
      "train epoch: 92 [1918/3918 (50%)\tLoss: 0.651781]\n",
      "test loss: 0.7832\n",
      "train epoch: 93 [0/3918 (0%)\tLoss: 0.604705]\n",
      "train epoch: 93 [1918/3918 (50%)\tLoss: 0.651468]\n",
      "test loss: 0.7829\n",
      "train epoch: 94 [0/3918 (0%)\tLoss: 0.604411]\n",
      "train epoch: 94 [1918/3918 (50%)\tLoss: 0.651153]\n",
      "test loss: 0.7825\n",
      "train epoch: 95 [0/3918 (0%)\tLoss: 0.604132]\n",
      "train epoch: 95 [1918/3918 (50%)\tLoss: 0.650841]\n",
      "test loss: 0.7821\n",
      "train epoch: 96 [0/3918 (0%)\tLoss: 0.603857]\n",
      "train epoch: 96 [1918/3918 (50%)\tLoss: 0.650543]\n",
      "test loss: 0.7817\n",
      "train epoch: 97 [0/3918 (0%)\tLoss: 0.603573]\n",
      "train epoch: 97 [1918/3918 (50%)\tLoss: 0.650238]\n",
      "test loss: 0.7813\n",
      "train epoch: 98 [0/3918 (0%)\tLoss: 0.603299]\n",
      "train epoch: 98 [1918/3918 (50%)\tLoss: 0.649931]\n",
      "test loss: 0.7810\n",
      "train epoch: 99 [0/3918 (0%)\tLoss: 0.603029]\n",
      "train epoch: 99 [1918/3918 (50%)\tLoss: 0.649614]\n",
      "test loss: 0.7806\n"
     ]
    }
   ],
   "source": [
    "# loop over the batches to train on the dataset for 100 times\n",
    "for epoch in range(100):\n",
    "    train(epoch, train_dataloader)\n",
    "    test(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18ef0cad-cbf5-4f36-b842-b8d294dabfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for xtest, ytest in test_dataloader:\n",
    "    pass\n",
    "y_test_pred = model(xtest).detach().numpy()\n",
    "ytest = ytest.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "605febd4-7ea9-495f-83ca-6a4bcff66d27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_test = yscaler.inverse_transform(ytest)\n",
    "y_test_pred = yscaler.inverse_transform(y_test_pred)\n",
    "ytest_summary = np.concatenate([y_test, y_test_pred], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e566704-60b5-41b2-ba6a-b9232dbc400f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.487374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.0</td>\n",
       "      <td>5.510200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.0</td>\n",
       "      <td>5.662288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.0</td>\n",
       "      <td>6.714055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.754687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.686732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>6.0</td>\n",
       "      <td>5.862689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>6.0</td>\n",
       "      <td>5.494952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>6.0</td>\n",
       "      <td>5.321161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.601471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>980 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     test  prediction\n",
       "0     5.0    5.487374\n",
       "1     6.0    5.510200\n",
       "2     7.0    5.662288\n",
       "3     8.0    6.714055\n",
       "4     5.0    5.754687\n",
       "..    ...         ...\n",
       "975   5.0    5.686732\n",
       "976   6.0    5.862689\n",
       "977   6.0    5.494952\n",
       "978   6.0    5.321161\n",
       "979   4.0    4.601471\n",
       "\n",
       "[980 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# showing the dataframe\n",
    "pd.DataFrame(ytest_summary, columns=['test', 'prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf95cbff-c9ba-4994-9b4c-5bb515afef7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the model and make prediction\n",
    "ytrain_pred_list = []\n",
    "ytrain_list = []\n",
    "for xtrain, ytrain in train_dataloader:\n",
    "    ytrain_pred_list.append(model(xtrain).detach().numpy())\n",
    "    ytrain_list.append(ytrain.detach().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5782359a-3a84-4eee-b7d4-4e05cac0c2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain_pred_list = np.concatenate(ytrain_pred_list)\n",
    "ytrain_list = np.concatenate(ytrain_list)\n",
    "\n",
    "ytrain_pred_list = yscaler.inverse_transform(ytrain_pred_list)\n",
    "ytrain_list = yscaler.inverse_transform(ytrain_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b660b88e-fa33-473f-b1e2-a6b4e5ffa210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score of NN trian set 0.35389745235443115\n",
      "Test score of NN test set 0.30862826108932495 \n",
      "\n",
      "Train mean error of NN trian set 0.54421335\n",
      "Test mean error of NN test set 0.605678 \n",
      "\n",
      "Train R2 of NN trian set 0.353871574559231\n",
      "Test R2 error of NN test set 0.3055026465948639\n"
     ]
    }
   ],
   "source": [
    "import fit_result\n",
    "fit_result.score('NN', ytrain_list, ytrain_pred_list, y_test, y_test_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
